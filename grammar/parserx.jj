options
{
    JAVA_UNICODE_ESCAPE = true;
    //LOOKAHEAD=3;
    STATIC = false;
}

PARSER_BEGIN(GParser)

package mesut.parserx.grammar;

import mesut.parserx.nodes.*;
import mesut.parserx.utils.*;
import java.io.*;
import java.util.ArrayList;
import java.util.List;

public class GParser
{
}

PARSER_END(GParser)

SKIP :
{
    " "  |   "\r"  |  "\n"  |  "\t"
}

MORE :
{
  "//" : IN_SINGLE_LINE_COMMENT
|
  <"/**" ~["/"]> { input_stream.backup(1); } : IN_FORMAL_COMMENT
|
  "/*" : IN_MULTI_LINE_COMMENT
}

<IN_SINGLE_LINE_COMMENT>
SPECIAL_TOKEN :
{
  <SINGLE_LINE_COMMENT: "\n" | "\r" | "\r\n" > : DEFAULT
}

<IN_FORMAL_COMMENT>
SPECIAL_TOKEN :
{
  <FORMAL_COMMENT: "*/" > : DEFAULT
}

<IN_MULTI_LINE_COMMENT>
SPECIAL_TOKEN :
{
  <MULTI_LINE_COMMENT: "*/" > : DEFAULT
}

<IN_SINGLE_LINE_COMMENT,IN_FORMAL_COMMENT,IN_MULTI_LINE_COMMENT>
MORE :
{
  < ~[] >
}

TOKEN :
{
  < LPAREN: "(" >
| < RPAREN: ")" >
| < LBRACE: "{" >
| < RBRACE: "}" >
| < LBRACKET: "[" >
| < RBRACKET: "]" >
| < SEMI: ";" >
| < COLON: ":" >
| < DOT: ".">
| < COMMA: "," >
| < QUOTE: "'" >
| < EQ: "=">
| < COLONEQ: ":=">
| < COLONCOLONEQ: "::=">
| < ARROW: "->">
| < STAR: "*">
| < PLUS: "+">
| < QUES: "?">
| < TILDE: "~">//read until
| < HASH: "#">
| < EMPTY: "%empty" | "%epsilon" | "Îµ">
}

TOKEN:
{
  <KEYWORD_TOKEN: "token">
| <KEYWORD_SKIP: "skip">
//| <STRING_LITERAL: "\"" (~["\r","\n","\""] | "\\\"")* "\"">
| <STRING_LITERAL: "\"" (~["\r","\n","\\","\""] | "\\" ~[])* "\"">
| <INCLUDE_DIRECTIVE: "include">
| <START_DIRECTIVE: "%start">
| <LEFT_DIRECTIVE: "%left">
| <RIGHT_DIRECTIVE: "%right">
}

TOKEN:
{
  <IDENT: (<CHAR> | "_") ( <CHAR> | ["0"-"9","_"])* >
| <#CHAR: ["a"-"z","A"-"Z"]>
| <#DIGIT: ["0"-"9"]>
| <#HEX_DIGIT: ["a"-"f","A"-"f","0"-"9"]>
| <#OCTAL_DIGIT: ["0"-"7"]>
| <ESCAPED_HEX: "\\x" (<HEX_DIGIT>)+ >
| <ESCAPED_OCTAL: "\\" (<OCTAL_DIGIT>)+ >
| <BRACKET_LIST: "["  (~["]"])* "]">
| <INTEGER: (<DIGIT>)+>
}


//--------parser rules-------------------
Tree tree(File file):
{
  Tree tree=new Tree();
  tree.file=file;
}
{
  (includeStatement(tree))*
  (LOOKAHEAD("token" "{")tokenBlock(tree) | LOOKAHEAD("skip" "{")skipBlock(tree))*
  [startDecl(tree)]
  (ruleDecl(tree) | assocDecl(tree)) *
  {
    return tree;
  }
}

void includeStatement(Tree tree):
{
  Token tok;
}
{
  "include" tok=<STRING_LITERAL>
  {
    tree.addInclude(UnicodeUtils.trimQuotes(tok.image));
  }
}

//lexer rules

void tokenBlock(Tree tree):
{
}
{
 "token" "{" tokenList(tree,false) "}"
}

void tokenList(Tree tree, boolean skip):
{}
{
 (tokenDecl(tree,skip))*
}

void tokenDecl(Tree tree,boolean skip):
{
  String name;
  boolean frag=false;
  TokenDecl decl;
  Node rhs;
}
{
  ("#"{frag=true;})? name = name() declSeparator() rhs = rhs() ";"
  {
    decl=new TokenDecl(name,rhs);
    decl.fragment=frag;
    if(skip){tree.addSkip(decl);}
    else{tree.addToken(decl);}
  }
}

void skipBlock(Tree tree):
{
}
{
 "skip" "{" tokenList(tree,true) "}"
}

void declSeparator():
{}
{
  "=" | ":" | ":=" | "->"
}

void assocDecl(Tree tree):
{
 Name nm;
 Assoc res=new Assoc();
}
{
  ("%left"{res.isLeft=true;} | "%right"{res.isLeft=false;}) (nm = ref(){ res.list.add(nm); })+ ";"
  {
    tree.assocList.add(res);
  }
}

void ruleDecl(Tree tree):
{
  RuleDecl decl=new RuleDecl();
  String name;
  Node rhs;
}
{
  name = name()[decl.args = args()] declSeparator() rhs = rhs() ";"
  {
    decl.name=name;
    decl.rhs=rhs;
    tree.addRule(decl);
  }
}


List<Name> args():
{
  List<Name> list = new ArrayList<>();
  String s;
}{
  "(" s = name(){list.add(new Name(s));} ("," s = name(){list.add(new Name(s));})* ")"  {
     return list;
  }
}

void startDecl(Tree tree):
{}
{
  "%start" declSeparator() tree.start = ref() ";"
}

//or list
Node rhs():
{
  Node rule;
  Or or = new Or();
}
{
  rule = orContent() { or.add(rule); }
   ("|" rule = orContent()
    {
      or.add(rule);
    })*
   { return or.normal(); }
}

Node orContent():
{
  Node node;
  Token label;
}
{
  node = sequence() ["#" label = <IDENT>{node.label = label.image;}]
  {
    return node;
  }
}

Node sequence():
{
  Sequence s = new Sequence();
  Node r;
}
{
  (r = regex(){s.add(r);})+
  {return s.normal();}
}

Node regex():
{
  Node rule;
}
{
  rule = named() [LOOKAHEAD(regexType()) (rule = regexType(rule))]
  { return rule; }
}

Node regexType(Node node):{}
{
 ("*" | "+" | "?")
  {
  return new Regex(node,getToken(0).image);
}
}

Node named():
{
 String name = null;
 Node node;
}
{
  (LOOKAHEAD(name() "=") name = name() "=")? node = simple()
  {
  if(name != null) node.varName = name;
  return node;
}
}

Node simple():
{
  Node rule;
}
{
  (rule = group()
   | rule = ref()
   | rule = stringNode()
   | rule = bracketNode()
   | rule = untilNode()
   | rule = dotNode()
   | <EMPTY>{rule = new Epsilon();})
   { return rule; }
}

Node dotNode():
{}
{
  <DOT>{
  return Dot.instance;
}
}
//[a-z]
Node bracketNode():
{
  Bracket b=new Bracket();
  Token t;
}
{
  t=<BRACKET_LIST>
  {
    b.parse(t.image);
    return b;
  }
}


Node group():
{
  Node rule;
}
{
  "(" rule = rhs() ")"
  {
  return new Group(rule);
}
}

Node untilNode():
{
  Node node;
}
{
  "~" node = regex() {return new Until(node);}
}


Node stringNode():
{
  Token tok;
}
{
  tok=<STRING_LITERAL>
  {
    return StringNode.from(tok.image);
  }
}

//token or rule
Name ref():
{
  String name;
}
{
  name = name(){
    return new Name(name);
  }
}

String name():
{
  Token token;
}
{
  token = <IDENT>{return token.image;}
}

/*Node repeatNode():
{
  Node node;
}
{
 "{" node = rhs() "}"{return new Regex(node, "*");}
}*/

/*Node optionalNode():
{
  Node node;
}
{
 "[" node = rhs() "]"{return new Regex(node, "?");}
}*/

