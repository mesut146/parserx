options
{
    JAVA_UNICODE_ESCAPE = true;
    //LOOKAHEAD=3;
    STATIC = false;
}

PARSER_BEGIN(GParser)

package mesut.parserx.grammar;

import mesut.parserx.nodes.*;
import mesut.parserx.utils.*;
import java.io.*;

public class GParser
{
}

PARSER_END(GParser)

SKIP :
{
    " "  |   "\r"  |  "\n"  |  "\t"
}

MORE :
{
  "//" : IN_SINGLE_LINE_COMMENT
|
  <"/**" ~["/"]> { input_stream.backup(1); } : IN_FORMAL_COMMENT
|
  "/*" : IN_MULTI_LINE_COMMENT
}

<IN_SINGLE_LINE_COMMENT>
SPECIAL_TOKEN :
{
  <SINGLE_LINE_COMMENT: "\n" | "\r" | "\r\n" > : DEFAULT
}

<IN_FORMAL_COMMENT>
SPECIAL_TOKEN :
{
  <FORMAL_COMMENT: "*/" > : DEFAULT
}

<IN_MULTI_LINE_COMMENT>
SPECIAL_TOKEN :
{
  <MULTI_LINE_COMMENT: "*/" > : DEFAULT
}

<IN_SINGLE_LINE_COMMENT,IN_FORMAL_COMMENT,IN_MULTI_LINE_COMMENT>
MORE :
{
  < ~[] >
}

TOKEN :
{
  < LPAREN: "(" >
| < RPAREN: ")" >
| < LBRACE: "{" >
| < RBRACE: "}" >
| < LBRACKET: "[" >
| < RBRACKET: "]" >
| < SEMI: ";" >
| < COLON: ":" >
| < DOT: ".">
| < COMMA: "," >
| < QUOTE: "'" >
| < EQ: "=">
| <COLONEQEQ: ":==">
| <COLONEQ: ":=">
| <ARROW: "->">
| < STAR: "*">
| < PLUS: "+">
| < QUES: "?">
| < XOR: "^">//negation
| < TILDE: "~">//read until
| < HASH: "#">
| <EMPTY: "%empty">
}

TOKEN:
{
  <KEYWORD_TOKEN: "token">
| <KEYWORD_TOKENS: "tokens">
| <KEYWORD_SKIP: "skip">
| <STRING_LITERAL: "\"" (~["\r","\n","\""] | "\\\"")* "\"">
| <INCLUDE_DIRECTIVE: "include">
| <START_SIRECTIVE: "@start">
}

TOKEN:
{
  <IDENT: (<CHAR> | "_") ( <CHAR> | ["0"-"9","_"])* >
| <#CHAR: ["a"-"z","A"-"Z"]>
| <#DIGIT: ["0"-"9"]>
| <#HEX_DIGIT: ["a"-"f","A"-"f","0"-"9"]>
| <#ESCAPED_SPECIAL: ("\\" ["a","b","e","f","n","r","t","v","\\","'","\"","?","s"])>
| <#OCTAL_DIGIT: ["0"-"7"]>
| <ESCAPED_HEX: "\\x" (<HEX_DIGIT>)+ >
| <ESCAPED_OCTAL: "\\" (<OCTAL_DIGIT>)+ >
| <#UNICODE: "\\u" <HEX_DIGIT> <HEX_DIGIT> <HEX_DIGIT> <HEX_DIGIT> >
//| <RANGE: <UNIT> "-" <UNIT> >
//| <UNIT: <UNICODE> | <ESCAPED_SPECIAL> | <ESCAPED_HEX> | <ESCAPED_OCTAL> >
| <BRACKET_LIST: "["  (~["]"])* "]">
| <INTEGER: (<DIGIT>)+>
}


//--------parser rules-------------------
Tree tree(File file):
{
  Tree tree=new Tree();
  tree.file=file;
}
{
  (includeStatement(tree))*
  (LOOKAHEAD("token" "{")tokenBlock(tree) | LOOKAHEAD("skip" "{")skipBlock(tree))*
  [startDecl(tree)]
  (ruleDecl(tree))*
  {
    return tree;
  }
}

void includeStatement(Tree tree):
{
  Token tok;
}
{
  "include" tok=<STRING_LITERAL>
  {
    tree.addInclude(UnicodeUtils.trimQuotes(tok.image));
  }
}

//lexer rules

void tokenBlock(Tree tree):
{
}
{
 "token" "{" tokenList(tree,false) "}"
}

void tokenList(Tree tree, boolean skip):
{}
{
 (tokenDecl(tree,skip))*
}

void tokenDecl(Tree tree,boolean skip):
{
  String name;
  boolean frag=false;
  TokenDecl decl;
  Node rhs;
}
{
  ("#"{frag=true;})? name = name() declSeparator() rhs = rhs() ";"
  {
    decl=new TokenDecl(name);
    decl.fragment=frag;
    decl.regex = rhs;
    if(skip){tree.addSkip(decl);}
    else{tree.addToken(decl);}
  }
}

void skipBlock(Tree tree):
{
}
{
 "skip" "{" tokenList(tree,true) "}"
}

void declSeparator():
{}
{
  "=" | ":" | ":==" | ":=" | "->"
}

void ruleDecl(Tree tree):
{
  RuleDecl decl=new RuleDecl();
  String name;
  Node rhs;
}
{
  name = name() declSeparator() rhs = rhs() ";"
  {
    decl.name=name;
    decl.rhs=rhs;
    tree.addRule(decl);
  }
}

void startDecl(Tree tree):
{}
{
  <START_SIRECTIVE> declSeparator() tree.start = ref() ";"
}

//or list
Node rhs():
{
  Node rule;
  Or or = new Or();
}
{
  rule = orContent() { or.add(rule); }
   ("|" rule = orContent()
    {
      or.add(rule);
    })*
   { return or.normal(); }
}

Node orContent():
{
  Node node;
  Token label;
}
{
  node = sequence() ["#" label = <IDENT>{node.label = label.image;}]
  {
    return node;
  }
}

Node sequence():
{
  Sequence s = new Sequence();
  Node r;
}
{
  (r = regex(){s.add(r);})+
  {return s.normal();}
}

Node regex():
{
  Node rule;
}
{
  rule = named() [LOOKAHEAD(regexType()) (rule = regexType(rule))]
  { return rule; }
}

Node regexType(Node node):{}
{
 ("*" | "+" | "?")
  {
  return new Regex(node,getToken(0).image);
}
}

Node named():
{
 String name = null;
 Node node;
}
{
  (LOOKAHEAD(name() "=") name = name() "=")? node = simple()
  {
  if(name != null) node.varName = name;
  return node;
}
}

Node simple():
{
  Node rule;
}
{
  (rule = group()
   | rule = ref()
   | rule = stringNode()
   | rule = bracketNode()
   | rule = untilNode()
   | rule = dotNode())
   { return rule; }
}

Node dotNode():
{}
{
  <DOT>{
  return Dot.instance;
}
}
//[a-z]
Node bracketNode():
{
  Bracket b=new Bracket();
  Token t;
}
{
  t=<BRACKET_LIST>
  {
    b.parse(t.image);
    return b;
  }
}


Node group():
{
  Node rule;
}
{
  "(" rule = rhs() ")"
  {
  return new Group(rule);
}
}

Node untilNode():
{
  Node node;
}
{
  "~" node = regex() {return new Until(node);}
}


Node stringNode():
{
  Token tok;
}
{
  tok=<STRING_LITERAL>
  {
    return StringNode.from(tok.image);
  }
}

Name lexerRef():
{
  String name;
}
{
 "{" name = name() "}"
 {
  return new Name(name,true);
}
}

Name ref():
{
  String name;
  Name ref;
}
{
  (name = name(){
    ref = new Name(name);
  }
  | ref = lexerRef() )
  {
    return ref;
  }
}

String name():
{
  Token token;
}
{
  token = <IDENT>{return token.image;}
}


Node repeatNode():
{
  Node node;
}
{
 "{" node = rhs() "}"{return new Regex(node, "*");}
}

Node optionalNode():
{
  Node node;
}
{
 "[" node = rhs() "]"{return new Regex(node, "?");}
}

/*Bracket bracket():
{
  Bracket b = new Bracket();
  Node node;
}
{
  "[" ["^"] (node = bracketUnit(){b.add(node);})+ "]"
  {
    return b;
  }
}*/

/*Node bracketUnit():
{}
{
 <RANGE>{

 } | <UNIT>{

 }
}*/