options
{
    JAVA_UNICODE_ESCAPE = true;
    //LOOKAHEAD=3;
    STATIC=false;
}

PARSER_BEGIN(GParser)

package grammar;

import nodes.*;
import rule.*;
import java.util.*;

public class GParser
{
 
}
PARSER_END(GParser)

SKIP :
{
    " "  |   "\r"  |  "\n"  |  "\t"
}

MORE :
{
  "//" : IN_SINGLE_LINE_COMMENT
|
  <"/**" ~["/"]> { input_stream.backup(1); } : IN_FORMAL_COMMENT
|
  "/*" : IN_MULTI_LINE_COMMENT
}

<IN_SINGLE_LINE_COMMENT>
SPECIAL_TOKEN :
{
  <SINGLE_LINE_COMMENT: "\n" | "\r" | "\r\n" > : DEFAULT
}

<IN_FORMAL_COMMENT>
SPECIAL_TOKEN :
{
  <FORMAL_COMMENT: "*/" > : DEFAULT
}

<IN_MULTI_LINE_COMMENT>
SPECIAL_TOKEN :
{
  <MULTI_LINE_COMMENT: "*/" > : DEFAULT
}

<IN_SINGLE_LINE_COMMENT,IN_FORMAL_COMMENT,IN_MULTI_LINE_COMMENT>
MORE :
{
  < ~[] >
}

TOKEN :
{
  < LPAREN: "(" >
| < RPAREN: ")" >
| < LBRACE: "{" >
| < RBRACE: "}" >
| < LBRACKET: "[" >
| < RBRACKET: "]" >
| < SEMI: ";" >
| < COLON: ":" >
| < DOT: ".">
| < COMMA: "," >
| < QUOTE: "'" >
| < EQ: "=">
| < STAR: "*">
| < PLUS: "+">
| < QUES: "?">
| < XOR: "^">
}

TOKEN:
{
  <TOKEN_: "token">
 |<TOKENS: "tokens">
 |<SKIP_: "skip">
 |<STRING_LITERAL: "\"" ((~["\r","\n"]))* "\"">
}

TOKEN:
{
  <IDENT: <CHAR> ( <CHAR> | ["0"-"9"] | "_" )*>
| <#CHAR: ["a"-"z","A"-"Z"]>
| < LEX_CHAR: ("\\" ["r","n","t","s"]) | <IDENT>>
}

Tree tree():
{
  Tree tree=new Tree();
}
{
  (tokenBlock(tree))?  (ruleDecl(tree))*
  {return tree;}
}

void tokenBlock(Tree tree):
{
}
{
 "tokens" "{" tokenList(tree,false) "}"
}

void tokenList(Tree tree,boolean skip):
{}
{
 (tokenDecl(tree,skip))*
}

void tokenDecl(Tree tree,boolean skip):
{
  String name;
  TokenDecl decl;
  Node rhs;
}
{
  name=name() "=" rhs=rhs()
  {
    decl=new TokenDecl(name);
    decl.regex=rhs;
    if(skip){tree.addSkip(decl);}
    else{tree.addToken(decl);}
  }
}

void skipBlock(Tree tree):
{
}
{
 "skip" "{" tokenList(tree,true) "}"
}

void ruleDecl(Tree tree):
{
  RuleDecl decl=new RuleDecl();
  String name;
  Node rhs;
}
{
  name=name() ("="|":") rhs=rhs()  ";"
  {
    decl.name=name;
    decl.rhs=rhs;
    tree.addRule(decl);
  }
}

//or series
Node rhs():
{
  Node rule;
  OrNode or=new OrNode();
  boolean more=false;
}
{
  rule=rhs_list(){or.add(rule);}
   ("|" rule=rhs_list()
    {
      or.add(rule);
      more=true;
    })*
   { return more?or:rule; }
}

//sequence no or
Node rhs_list():
{
  Sequence s=new Sequence();
  Node r;
}
{
  (r=regex(){s.add(r);})+
  {return s.normal();}
}

Node regex():
{
  Node rule;
  RegexNode regex;
}
{
  rule=simple(){regex=new RegexNode(rule);}
   ("*"{regex.star=true;}
  | "+"{regex.plus=true;}
  | "?"{regex.optional=true;})?{return regex;}
     {return rule;}
}

Node simple():
{
  Node rule;
}
{
  (rule=groupRule()
   | rule=nameRule()
   | rule=stringNode()
   | rule=bracketNode()){return rule;}
}

Node bracketNode():
{
  Bracket b=new Bracket();
  Node n;
  String s;
  Token chr;
}
{
  "[" ("^"{b.negate=true;})?
   (LOOKAHEAD(range()) n=range(){b.add(n);}
  |chr=<LEX_CHAR>{b.add(chr.image.charAt(0));})*
   "]"
  {return b;}
}

Node range():
{
  Token s1,s2;
}
{
  s1=<LEX_CHAR> "-" s2=<LEX_CHAR>
  {return new RangeNode(s1.image,s2.image);}
}

Node stringNode():
{
  Token str;
}
{
  str=<STRING_LITERAL>{return new StringNode(str.image);}
}

Node groupRule():
{
  GroupNode group=new GroupNode();
  Node rule;
}
{
  "(" rule=rhs() ")"
  {
    group.rhs=rule;
    return group;
  }
}

Node nameRule():
{
  String name;
}
{
  name=name(){return new RuleRef(name);}
}

String name():
{
  Token token;
}
{
  token=<IDENT>{return token.image;}
}
